"""Kçº¿æ•°æ®ç¼“å­˜æœåŠ¡"""
from .models import CandlestickCache
from .plugin_adapter import get_unified_service
from .services import MarketAPIError
from django.db import transaction
from django.db.utils import OperationalError
from decimal import Decimal
import logging
import time

logger = logging.getLogger(__name__)


class CandlestickCacheService:
    """Kçº¿æ•°æ®ç¼“å­˜æœåŠ¡ - è´Ÿè´£æ•°æ®åº“ç¼“å­˜çš„è¯»å†™"""
    
    @staticmethod
    def get_from_cache(source: str, symbol: str, bar: str, limit: int = 100, 
                      before: int = None, after: int = None):
        """ä»ç¼“å­˜è·å–Kçº¿æ•°æ®
        
        Args:
            source: æ•°æ®æº
            symbol: äº¤æ˜“å¯¹
            bar: æ—¶é—´å‘¨æœŸ
            limit: è¿”å›æ•°é‡
            before: è·å–è¯¥æ—¶é—´æˆ³ä¹‹å‰çš„æ•°æ®ï¼ˆç§’ï¼‰
            after: è·å–è¯¥æ—¶é—´æˆ³ä¹‹åçš„æ•°æ®ï¼ˆç§’ï¼‰
        
        Returns:
            list: Kçº¿æ•°æ®åˆ—è¡¨
        """
        queryset = CandlestickCache.objects.filter(
            source=source,
            symbol=symbol,
            bar=bar
        )
        
        if before:
            queryset = queryset.filter(time__lt=before)
        
        if after:
            queryset = queryset.filter(time__gt=after)
        
        # æ ¹æ®æ—¶é—´å€’åºæ’åºï¼Œå–æœ€æ–°çš„limitæ¡
        candles = queryset.order_by('-time')[:limit]
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ­£åºè¿”å›
        result = []
        for candle in reversed(list(candles)):
            result.append({
                'time': candle.time,
                'open': float(candle.open),
                'high': float(candle.high),
                'low': float(candle.low),
                'close': float(candle.close),
                'volume': float(candle.volume),
            })
        
        return result
    
    @staticmethod
    def save_to_cache(source: str, symbol: str, bar: str, candles: list, max_retries: int = 3):
        """æ‰¹é‡ä¿å­˜Kçº¿æ•°æ®åˆ°ç¼“å­˜
        
        Args:
            source: æ•°æ®æº
            symbol: äº¤æ˜“å¯¹
            bar: æ—¶é—´å‘¨æœŸ
            candles: Kçº¿æ•°æ®åˆ—è¡¨
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        if not candles:
            return 0
        
        created_count = 0
        updated_count = 0
        
        for attempt in range(max_retries):
            try:
                with transaction.atomic():
                    for candle in candles:
                        obj, created = CandlestickCache.objects.update_or_create(
                            source=source,
                            symbol=symbol,
                            bar=bar,
                            time=candle['time'],
                            defaults={
                                'open': Decimal(str(candle['open'])),
                                'high': Decimal(str(candle['high'])),
                                'low': Decimal(str(candle['low'])),
                                'close': Decimal(str(candle['close'])),
                                'volume': Decimal(str(candle['volume'])),
                            }
                        )
                        if created:
                            created_count += 1
                        else:
                            updated_count += 1
                
                logger.info(f"Saved {created_count} new, updated {updated_count} candles for {source}/{symbol}/{bar}")
                return created_count
                
            except OperationalError as e:
                if 'database is locked' in str(e) and attempt < max_retries - 1:
                    wait_time = 0.1 * (2 ** attempt)  # æŒ‡æ•°é€€é¿: 0.1s, 0.2s, 0.4s
                    logger.warning(f"Database locked, retrying in {wait_time}s (attempt {attempt + 1}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    logger.error(f"Failed to save to cache after {attempt + 1} attempts: {e}")
                    raise
        
        return created_count
    
    @staticmethod
    def get_cache_range(source: str, symbol: str, bar: str):
        """è·å–ç¼“å­˜çš„æ•°æ®èŒƒå›´ï¼ˆä½¿ç”¨èšåˆæŸ¥è¯¢ä¼˜åŒ–æ€§èƒ½ï¼‰
        
        Returns:
            dict: {'oldest': timestamp, 'newest': timestamp, 'count': int}
        """
        from django.db.models import Min, Max, Count
        
        result = CandlestickCache.objects.filter(
            source=source,
            symbol=symbol,
            bar=bar
        ).aggregate(
            oldest=Min('time'),
            newest=Max('time'),
            count=Count('id')
        )
        
        return {
            'oldest': result['oldest'],
            'newest': result['newest'],
            'count': result['count'] or 0
        }
    
    @staticmethod
    def fetch_and_cache(source: str, symbol: str, bar: str, limit: int = 1000, before: int = None):
        """ä»APIè·å–æ•°æ®å¹¶å¼‚æ­¥ç¼“å­˜ï¼ˆä¸é˜»å¡è¿”å›ï¼‰
        
        Args:
            source: æ•°æ®æº
            symbol: äº¤æ˜“å¯¹
            bar: æ—¶é—´å‘¨æœŸ
            limit: è·å–æ•°é‡
            before: è·å–è¯¥æ—¶é—´æˆ³ä¹‹å‰çš„æ•°æ®ï¼ˆæ¯«ç§’ï¼‰
        
        Returns:
            list: Kçº¿æ•°æ®
        """
        try:
            # ä½¿ç”¨ç»Ÿä¸€æœåŠ¡ï¼ˆä¼˜å…ˆæ’ä»¶ç³»ç»Ÿï¼‰
            service = get_unified_service(source)
            candles = service.get_candlesticks(inst_id=symbol, bar=bar, limit=limit, before=before)
            
            # æ—¥å¿—æ ‡è®°æ•°æ®æ¥æº
            if service.is_using_plugin:
                logger.info(f"ğŸ“¦ ä½¿ç”¨æ’ä»¶è·å– {source}/{symbol}/{bar}: {len(candles)} æ¡")
            else:
                logger.info(f"ğŸ”§ ä½¿ç”¨æ—§æœåŠ¡è·å– {source}/{symbol}/{bar}: {len(candles)} æ¡")
            
            # å¼‚æ­¥ä¿å­˜åˆ°ç¼“å­˜ï¼ˆä¸ç­‰å¾…ç»“æœï¼Œé¿å…é˜»å¡ï¼‰
            if candles:
                try:
                    CandlestickCacheService.save_to_cache(source, symbol, bar, candles, max_retries=1)
                except Exception as e:
                    # ç¼“å­˜å¤±è´¥ä¸å½±å“æ•°æ®è¿”å›
                    logger.warning(f"Failed to cache data (non-blocking): {e}")
            
            return candles
        except MarketAPIError as e:
            logger.error(f"Failed to fetch from {source}: {e}")
            raise
    
    @staticmethod
    def get_with_auto_fetch(source: str, symbol: str, bar: str, limit: int = 100,
                           before: int = None, after: int = None):
        """æ™ºèƒ½è·å–æ•°æ®ï¼šä¼˜å…ˆä»ç¼“å­˜è·å–ï¼Œç¼“å­˜ä¸è¶³æ—¶ä»APIè¡¥å……
        
        ç­–ç•¥ï¼š
        1. å…ˆä»ç¼“å­˜è·å–æ•°æ®
        2. å¦‚æœç¼“å­˜æ•°æ®å……è¶³ï¼ˆâ‰¥limitï¼‰ï¼Œç›´æ¥è¿”å›
        3. å¦‚æœç¼“å­˜æ•°æ®ä¸è¶³ï¼Œä»APIè¡¥å……å¹¶ç¼“å­˜
        
        Args:
            source: æ•°æ®æº
            symbol: äº¤æ˜“å¯¹
            bar: æ—¶é—´å‘¨æœŸ
            limit: è¿”å›æ•°é‡
            before: è·å–è¯¥æ—¶é—´æˆ³ä¹‹å‰çš„æ•°æ®ï¼ˆç§’ï¼‰
            after: è·å–è¯¥æ—¶é—´æˆ³ä¹‹åçš„æ•°æ®ï¼ˆç§’ï¼‰
        
        Returns:
            list: Kçº¿æ•°æ®
        """
        # é¦–å…ˆå°è¯•ä»ç¼“å­˜è·å–
        cached_data = CandlestickCacheService.get_from_cache(
            source, symbol, bar, limit, before, after
        )
        
        # å¦‚æœç¼“å­˜æ•°æ®å……è¶³ï¼Œç›´æ¥è¿”å›
        if len(cached_data) >= limit:
            logger.info(f"âœ… Cache hit: {len(cached_data)} candles from cache")
            return cached_data
        
        # ç¼“å­˜æ•°æ®ä¸è¶³ï¼Œä»APIè·å–å¹¶è¡¥å……
        logger.info(f"âš ï¸ Cache miss or insufficient: {len(cached_data)}/{limit}, fetching from API...")
        
        try:
            # è½¬æ¢beforeä¸ºæ¯«ç§’ï¼ˆAPIéœ€è¦ï¼‰
            before_ms = before * 1000 if before else None
            
            # ä»APIè·å–ï¼ˆä¼šè‡ªåŠ¨ç¼“å­˜ï¼‰
            api_data = CandlestickCacheService.fetch_and_cache(
                source, symbol, bar, limit, before_ms
            )
            
            # å¦‚æœæœ‰afterå‚æ•°ï¼Œè¿‡æ»¤æ•°æ®
            if after and api_data:
                filtered_data = [c for c in api_data if c['time'] > after]
                logger.info(f"âœ… API success: {len(filtered_data)} candles after {after}")
                return filtered_data
            
            logger.info(f"âœ… API success: {len(api_data)} candles")
            return api_data
            
        except MarketAPIError as e:
            # APIå¤±è´¥æ—¶ï¼Œè¿”å›ç¼“å­˜æ•°æ®ï¼ˆå³ä½¿ä¸è¶³ï¼‰
            if cached_data:
                logger.warning(f"âš ï¸ API failed, returning cached data: {len(cached_data)} candles")
                return cached_data
            else:
                logger.error(f"âŒ API failed and no cached data available")
                raise
